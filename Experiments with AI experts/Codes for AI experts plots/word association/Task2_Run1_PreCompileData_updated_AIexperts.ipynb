{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "841a43ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## extract dataset for validity tests; remove cue words where guess words between humans and machines overlap\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "cue_words_list = np.load('Data_all/all_cue_words_october_1.npy')\n",
    "CueGuessWords = {}\n",
    "\n",
    "for w in cue_words_list:\n",
    "    #print(w)\n",
    "    CueGuessWords[w] = {'human':[],'AI':[]}\n",
    "\n",
    "    \n",
    "numfiles = 150\n",
    "numfolders = 5\n",
    "\n",
    "for identity in ['human','AI']:\n",
    "    for fo in range(numfolders):\n",
    "        for fi in range(numfiles):\n",
    "            filename = identity + '/' + str(fo) + '/' + str(fi) + '.html'\n",
    "\n",
    "            with open('./dataset/' + filename) as f:\n",
    "                lines = f.readlines()\n",
    "                #print(lines)\n",
    "                cueword = lines[0].split('<p>Cue: ')[1].split(';')[0]\n",
    "                #print(cueword)\n",
    "                guessword = lines[0].split('; Association: ')[1].split(' </p>')[0]\n",
    "                #print(guessword)\n",
    "                CueGuessWords[cueword][identity].append(guessword)\n",
    "\n",
    "#print(CueGuessWords)\n",
    "\n",
    "for w in cue_words_list:\n",
    "    #print(w)\n",
    "    strlistH = CueGuessWords[w]['human']\n",
    "    strlistM = CueGuessWords[w]['AI']\n",
    "    flag = bool(set(strlistH).intersection(strlistM))\n",
    "#     if not flag:\n",
    "#         print(w)\n",
    "#         print(strlistH)\n",
    "#         print(strlistM)\n",
    "    CueGuessWords[w]['flag'] = flag\n",
    "\n",
    "#flag: 1 -> invalid; NOT use\n",
    "#flag: 0 -> valid; use\n",
    "with open(\"./savedResults/DataValidity.json\", \"w\") as fp:\n",
    "    json.dump(CueGuessWords,fp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5102957e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b': 'word2vec', 'c': 'gpt2', 'd': 'gpt3 (embedding)', 'e': 'gpt3 (prompt curie)', 'f': 'gpt3 (prompt davinvci)', 'g': 'other'}\n",
      "=======================\n",
      "AIexperts\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'CueGuessWords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5y/60d837ps00s6_lbr07dlqtwh0000gn/T/ipykernel_19869/3940721089.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    118\u001b[0m                         \u001b[0mcaption\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcue_words_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimageID\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# cue word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                         \u001b[0;32mif\u001b[0m \u001b[0mCueGuessWords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcaption\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'flag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m                             \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0;31m#print('invalid')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CueGuessWords' is not defined"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "link response to model number\n",
    "\"\"\"\n",
    "def find_real_from_response(response):\n",
    "    response = response.split('.')[0]; response = response.split('_'); \n",
    "    model = response[-2]\n",
    "    #if model == 'AI' :\n",
    "    #try :\n",
    "    #int(response[-2])\n",
    "    model_num =  int(response[-1])\n",
    "    #except:\n",
    "    #else:\n",
    "    #model_num = 0; model = response[-2]\n",
    "    return model, model_num\n",
    "\n",
    "\"\"\"\n",
    "numbers to models names\n",
    "\"\"\"\n",
    "#dict_numbers_to_model_name = np.load('Data_all/dict_numbers_to_model_name.npy',allow_pickle=True).item() # the location is C:\\Users\\noga mudrik\\Documents\\turing_associations\\all_important_code_files\n",
    "# dict_numbers_to_model_name = {0: 'word2vec',\n",
    "#  1: 'gpt2',\n",
    "#  2: 'gpt3 (embedding)',\n",
    "#  3: 'gpt3 (prompt curie)',\n",
    "#  4: 'gpt3 (prompt davinvci)'}\n",
    "## Elisa: Ok, so the convention is the following: a = human, b = word2vec, c = gpt2, d = gpt3 (embedding), e = gpt3 (prompt curie), f = gpt3 (prompt davinci), g = catch trials\n",
    "dict_numbers_to_model_name = {'b': 'word2vec',\n",
    " 'c': 'gpt2',\n",
    " 'd': 'gpt3 (embedding)',\n",
    " 'e': 'gpt3 (prompt curie)',\n",
    " 'f': 'gpt3 (prompt davinvci)', \n",
    " 'g': 'other'}\n",
    "\n",
    "possible_models = dict_numbers_to_model_name.values()\n",
    "print(dict_numbers_to_model_name)\n",
    "\n",
    "dict_gender_results = np.load('Data_all/dict_gender_results.npy', allow_pickle=True).item()\n",
    "\n",
    "cue_words_list = np.load('Data_all/all_cue_words_october_1.npy')\n",
    "\n",
    "results = {'inlab':[], 'inlab_gender':[], 'inlab_nogender':[], 'mturk':[], 'machine':[], 'combined':[]}\n",
    "results = {'AIexperts': []}\n",
    "\n",
    "\n",
    "############# for jason file processing (inlab)\n",
    "jsonpath = './Data_all/'\n",
    "# filenames = {'inlab': ['word_association_inlab_gender_15','word_association_inlab_no_gender_15'],\n",
    "#              'inlab_gender': ['word_association_inlab_gender_15'],\n",
    "#              'inlab_nogender': ['word_association_inlab_no_gender_15']}\n",
    "filenames = {'AIexperts': ['participants']}\n",
    "\n",
    "for key in filenames:\n",
    "    print(\"=======================\")\n",
    "    print(key)\n",
    "\n",
    "    count = 0\n",
    "    trials_dict = {}\n",
    "    workercount = 0\n",
    "    \n",
    "    for dbfilename in filenames[key]:\n",
    "        #print(\"=======================\")\n",
    "        #print(jasonfilename)\n",
    "        conn = sqlite3.connect(jsonpath + dbfilename + \".db\")\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"select * from TuringAssociationAI_turing;\")        \n",
    "        all_data = cursor.fetchall()\n",
    "                \n",
    "        for i in range(0, len(all_data)):\n",
    "            if (all_data[i][15] == 3 and all_data[i][17] is not None): #check status \n",
    "                data_dict = json.loads(all_data[i][17])\n",
    "                workercount += 1\n",
    "                \n",
    "                for dat in data_dict['data']:\n",
    "                    if dat['trialdata']['phase'] == 'TEST':\n",
    "                        count += 1\n",
    "                        trial_data = {}\n",
    "                        trial_data['workerID'] = data_dict['workerId']\n",
    "                        #print(data_dict['workerId'])\n",
    "                        trial_data['workerData'] = data_dict['questiondata']\n",
    "                        curres = dat['trialdata']\n",
    "                        rt = curres['rt'] ###\n",
    "                        if 'hit' in curres.keys():\n",
    "                            hit = curres['hit'] ###\n",
    "                        elif 'page_name' in curres.keys():\n",
    "                            page_name = curres['page_name']\n",
    "                            hit = page_name.split('/')[-1]\n",
    "                        trial = curres['trial']\n",
    "                        \n",
    "                        guess = curres['Aclass']; #print(guess); print(model_real)\n",
    "                        response_speaker = guess ###\n",
    "                        if response_speaker == 'AI':\n",
    "                            response_speaker = 'machine'\n",
    "                        \n",
    "                        #print(curres['prompt'])\n",
    "                        groundtruth, model_num = find_real_from_response(hit)#response\n",
    "                        \n",
    "                        if  groundtruth == 'a':\n",
    "                            groundtruth = 'human'\n",
    "                            #curres_split = curres['AssociationID'][:-5].split('/')\n",
    "                            #real_gender = dict_gender_results[int(curres_split[-2])][int(curres_split[-1])]\n",
    "                            machine_groundtruth = ''\n",
    "                            human_groundtruth = 'human'\n",
    "                        else:\n",
    "                            #real_gender = ''\n",
    "                            machine_groundtruth = dict_numbers_to_model_name[groundtruth]\n",
    "                            human_groundtruth = ''\n",
    "                            groundtruth = 'machine'\n",
    "                            #print(machine_groundtruth)\n",
    "                        \n",
    "                        \n",
    "                        imageID = int(hit.split('.')[0].split('_')[-3])\n",
    "                        caption = cue_words_list[imageID] # cue word\n",
    "                        \n",
    "                        if CueGuessWords[caption]['flag']:\n",
    "                            count = count - 1\n",
    "                            #print('invalid')\n",
    "                            continue\n",
    "                        \n",
    "                        counterbalance = 0\n",
    "\n",
    "                        phase = curres['phase']\n",
    "                        \n",
    "                        if 'guess_gender' in curres.keys():\n",
    "                            guess_gender = curres['guess_gender']\n",
    "                            if guess_gender == 'm': \n",
    "                                guess_gender_long = 'male' # guess gender\n",
    "                            else:\n",
    "                                guess_gender_long = 'female' # guess gender\n",
    "\n",
    "                            trialData_save = {'rt':rt, 'hit':hit, 'trial':trial, \n",
    "                                          'response_speaker':response_speaker,\n",
    "                                          'machine_groundtruth':machine_groundtruth,'imageID':imageID,\n",
    "                                          'caption': caption, 'counterbalance':counterbalance,\n",
    "                                          'groundtruth':groundtruth,\n",
    "                                          'phase':phase, 'human_groundtruth':human_groundtruth}\n",
    "                                          #'real_gender':real_gender, 'response_gender':guess_gender_long\n",
    "                        else:\n",
    "                            trialData_save = {'rt':rt, 'hit':hit, 'trial':trial, \n",
    "                                          'response_speaker':response_speaker,\n",
    "                                          'machine_groundtruth':machine_groundtruth,'imageID':imageID,\n",
    "                                          'caption': caption, 'counterbalance':counterbalance,\n",
    "                                          'groundtruth':groundtruth,\n",
    "                                          'phase':phase, 'human_groundtruth':human_groundtruth}\n",
    "                                          #'real_gender':real_gender}                       \n",
    "                        \n",
    "                        \n",
    "                        trial_data['trialData'] = trialData_save\n",
    "                        trials_dict['Trial_'+str(count)] = trial_data\n",
    "\n",
    "        conn.close()\n",
    "    results[key] = trials_dict\n",
    "    #print(trials_dict)\n",
    "        #json.dump(trials_dict, open(\"./turing_inlab_no_gender_img_caption_half.json\",\"w\"))\n",
    "        \n",
    "    print(workercount, ' workers')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "292dc197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All AI expert data is extracted.\n",
      "There are [AIexperts; 391]\n",
      "Compilation completed! Results are saved to folder!\n"
     ]
    }
   ],
   "source": [
    "print('All AI expert data is extracted.')\n",
    "for key in results:\n",
    "    print('There are [' + key + '; ' + str(len(results[key])) + ']')\n",
    "    \n",
    "#save the compiled results as jason\n",
    "with open(\"./savedResults_elisa/compiled_AIexperts.json\", \"w\") as fp:\n",
    "    json.dump(results,fp) \n",
    "    \n",
    "print('Compilation completed! Results are saved to folder!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7966df8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mturk\n",
      "71  workers\n",
      "mturk\n",
      "71  workers\n"
     ]
    }
   ],
   "source": [
    "########### mturk jason files\n",
    "dbfile = 'Data_all/participants_28_mturk.db'\n",
    "cnx = sqlite3.connect(dbfile)\n",
    "df = pd.read_sql_query(\"SELECT * FROM 'TuringAssociationAI_turing'\", cnx)#TuringAssociationAI_turing\n",
    "\n",
    "## pre-process db files; NOT all db entries are usable...\n",
    "vals = df['beginhit'].values\n",
    "locs_vals = [i for i,v in enumerate(vals) if (v.startswith('2022-10-27') or v.startswith('2022-10-28'))]\n",
    "df = df.iloc[locs_vals,:]\n",
    "df = df.sort_values(by='beginhit')#['beginhit']\n",
    "df = df.iloc[-80:,:]\n",
    "\n",
    "res_per_subject = {i: json.loads(df['datastring'][i])  \n",
    "                        for i in df['datastring'].index.values \n",
    "                        if (df['datastring'][i])} \n",
    "\n",
    "key = 'mturk'\n",
    "count = 0\n",
    "trials_dict = {}\n",
    "workercount = 0\n",
    "\n",
    "for sub,res_per_subject_subject in res_per_subject.items():\n",
    "    workerData = res_per_subject_subject['questiondata']\n",
    "    workerID = res_per_subject_subject['workerId']\n",
    "    flag = 0\n",
    "    for res_per_subject_subject_spec in res_per_subject_subject['data']:\n",
    "        if 'trialdata' in res_per_subject_subject_spec:           \n",
    "            if 'prompt' in res_per_subject_subject_spec['trialdata']:\n",
    "                flag = 1\n",
    "                curres = res_per_subject_subject_spec['trialdata']\n",
    "                \n",
    "                count += 1\n",
    "                trial_data = {}\n",
    "                trial_data['workerID'] = workerID\n",
    "                #print(data_dict['workerId'])\n",
    "                trial_data['workerData'] = workerData\n",
    "                \n",
    "                rt = curres['rt'] ###\n",
    "                hit = curres['hit'] ###\n",
    "                trial = curres['trial']\n",
    "\n",
    "                guess = curres['guess_decision']; #print(guess); print(model_real)\n",
    "                response_speaker = guess ###\n",
    "                if response_speaker == 'AI':\n",
    "                    response_speaker = 'machine'\n",
    "\n",
    "                #print(curres['prompt'])\n",
    "                groundtruth, model_num = find_real_from_response(curres['prompt'])#response\n",
    "\n",
    "                if  groundtruth == 'human':\n",
    "\n",
    "                    curres_split = curres['AssociationID'][:-5].split('/')\n",
    "                    real_gender = dict_gender_results[int(curres_split[-2])][int(curres_split[-1])]\n",
    "                    machine_groundtruth = ''\n",
    "                    human_groundtruth = 'human'\n",
    "                else:\n",
    "                    groundtruth = 'machine'\n",
    "                    real_gender = ''\n",
    "                    machine_groundtruth = dict_numbers_to_model_name[model_num]\n",
    "                    human_groundtruth = ''\n",
    "                    #print(machine_groundtruth)\n",
    "\n",
    "\n",
    "                imageID = int(curres['prompt'].split('.')[0].split('/')[-1])\n",
    "                caption = cue_words_list[imageID] # cue word\n",
    "                counterbalance = 0\n",
    "\n",
    "                if CueGuessWords[caption]['flag']:\n",
    "                    count = count - 1\n",
    "                    continue\n",
    "                \n",
    "                phase = curres['phase']\n",
    "\n",
    "                if 'guess_gender' in curres.keys():\n",
    "                    guess_gender = curres['guess_gender']\n",
    "                    if guess_gender == 'm': \n",
    "                        guess_gender_long = 'male' # guess gender\n",
    "                    else:\n",
    "                        guess_gender_long = 'female' # guess gender\n",
    "\n",
    "                    trialData_save = {'rt':rt, 'hit':hit, 'trial':trial, \n",
    "                                  'response_speaker':response_speaker,\n",
    "                                  'machine_groundtruth':machine_groundtruth,'imageID':imageID,\n",
    "                                  'caption': caption, 'counterbalance':counterbalance,\n",
    "                                  'groundtruth':groundtruth,\n",
    "                                  'phase':phase, 'human_groundtruth':human_groundtruth ,\n",
    "                                  'real_gender':real_gender, 'response_gender':guess_gender_long}\n",
    "                else:\n",
    "                    trialData_save = {'rt':rt, 'hit':hit, 'trial':trial, \n",
    "                                  'response_speaker':response_speaker,\n",
    "                                  'machine_groundtruth':machine_groundtruth,'imageID':imageID,\n",
    "                                  'caption': caption, 'counterbalance':counterbalance,\n",
    "                                  'groundtruth':groundtruth,\n",
    "                                  'phase':phase, 'human_groundtruth':human_groundtruth,\n",
    "                                  'real_gender':real_gender}                       \n",
    "\n",
    "\n",
    "                trial_data['trialData'] = trialData_save\n",
    "                trials_dict['Trial_'+str(count)] = trial_data\n",
    "        \n",
    "    if flag == 1:\n",
    "        workercount = workercount + 1\n",
    "        \n",
    "results[key] = trials_dict  \n",
    "#print(trials_dict)\n",
    "print(key)\n",
    "print(workercount, ' workers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "955f503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### AI jason files\n",
    "#### pending Noga's results; remove invalid cue words\n",
    "\n",
    "key = 'machine'\n",
    "count = 0\n",
    "trials_dict = {}\n",
    "\n",
    "with open(\"./Data_all/dict_cue_guess_full_who_Said_1500.json\", 'r') as f:\n",
    "    cuelist = json.load(f)\n",
    "\n",
    "json_file_path_list = ['AI_judge_new_structure_for_dict_WORD2VEC_1500_judge',\n",
    "                  'AI_judge_new_structure_for_dict_GPT2_1500_judge',\n",
    "                  'AI_judge_new_structure_for_dict_GPT3_1500_judge']\n",
    "\n",
    "#json_file_path_list = ['AI_judge_new_structure_for_dict_WORD2VEC_1500_judge']\n",
    "    \n",
    "aijudgename = ['word2vec','gpt2','gpt3']\n",
    "taboo_machine_groundtruth = ['word2vec','gpt2','gpt3 (embedding)']\n",
    "#the taboo phrase exlucdes trials where ai judge is the same as the ai agent\n",
    "\n",
    "for i, json_file_path in enumerate(json_file_path_list): \n",
    "    judgename = aijudgename[i]\n",
    "    tabooname = taboo_machine_groundtruth[i]\n",
    "    \n",
    "    with open(jsonpath + json_file_path + '.json', 'r') as j:\n",
    "        contents = json.loads(j.read())\n",
    "        #results['machine'] = contents\n",
    "        #print(contents)\n",
    "        for trialid in contents:\n",
    "            \n",
    "            count += 1\n",
    "            trial_data = {}\n",
    "            trial_data['workerID'] = judgename\n",
    "            \n",
    "            cueword = cuelist[trialid]['cue']\n",
    "            if CueGuessWords[cueword]['flag']:\n",
    "                count = count - 1\n",
    "                #print('happend!')\n",
    "                continue\n",
    "                    \n",
    "            trialinfor = contents[trialid]\n",
    "            trial = trialinfor['trial']\n",
    "            response_speaker = trialinfor['response_speaker']\n",
    "            machine_groundtruth = trialinfor['machine_groundtruth']\n",
    "            \n",
    "            if response_speaker == 'AI':\n",
    "                response_speaker = 'machine'\n",
    "            else:\n",
    "                response_speaker = 'human'\n",
    "            \n",
    "            if machine_groundtruth == 'human':\n",
    "                groundtruth = 'human'\n",
    "                machine_groundtruth = ''\n",
    "                human_groundtruth = 'human'\n",
    "            else:\n",
    "                groundtruth = 'machine'\n",
    "                human_groundtruth = ''\n",
    "                if machine_groundtruth == ' gpt3 (embedding)':\n",
    "                    machine_groundtruth = 'gpt3 (embedding)'\n",
    "            \n",
    "            if tabooname == machine_groundtruth:\n",
    "                count = count - 1\n",
    "                #print('happend; taboo')\n",
    "                continue\n",
    "                \n",
    "            trialData_save = {'trial':trial,\n",
    "                                  'caption': cueword,\n",
    "                                  'response_speaker':response_speaker,\n",
    "                                  'machine_groundtruth':machine_groundtruth,                                  \n",
    "                                  'groundtruth':groundtruth,\n",
    "                                  'human_groundtruth':human_groundtruth}\n",
    "            #print(trialData_save)\n",
    "            trial_data['trialData'] = trialData_save\n",
    "            trials_dict['Trial_'+str(count)] = trial_data\n",
    "        \n",
    "    \n",
    "results['machine'] = trials_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5635930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save combined results\n",
    "count = 0\n",
    "trials_dict = {}\n",
    "for ke in ['inlab','mturk']:\n",
    "    for it in results[ke]:\n",
    "        count = count + 1\n",
    "        trialin = results[ke][it]\n",
    "        trials_dict['Trial_'+str(count)] = trialin\n",
    "        \n",
    "results['combined'] = trials_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f3602a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data is extracted.\n",
      "There are [inlab; 843]\n",
      "There are [inlab_gender; 415]\n",
      "There are [inlab_nogender; 428]\n",
      "There are [mturk; 1930]\n",
      "There are [machine; 2241]\n",
      "There are [combined; 2773]\n",
      "All data is extracted.\n",
      "There are [inlab; 843]\n",
      "There are [inlab_gender; 415]\n",
      "There are [inlab_nogender; 428]\n",
      "There are [mturk; 1930]\n",
      "There are [machine; 2241]\n",
      "There are [combined; 2773]\n",
      "Compilation completed! Results are saved to folder!\n",
      "Compilation completed! Results are saved to folder!\n"
     ]
    }
   ],
   "source": [
    "print('All data is extracted.')\n",
    "for key in results:\n",
    "    print('There are [' + key + '; ' + str(len(results[key])) + ']')\n",
    "    \n",
    "#save the compiled results as jason\n",
    "with open(\"./savedResults/compiled.json\", \"w\") as fp:\n",
    "    json.dump(results,fp) \n",
    "    \n",
    "print('Compilation completed! Results are saved to folder!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b448be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
