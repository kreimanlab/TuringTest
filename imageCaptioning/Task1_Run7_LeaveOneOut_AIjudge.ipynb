{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ce29b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 4096)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "# human = label 0\n",
    "# AI = label 1\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "\n",
    "foldername = './Data_all/AIembeddings/'\n",
    "human_embeddings = np.load(foldername + 'human_embeddings_curie.npy')\n",
    "ofa_embeddings = np.load(foldername + 'ofa_embeddings_curie.npy')\n",
    "git_embeddings = np.load(foldername + 'git_embeddings_curie.npy')\n",
    "clipcap_embeddings = np.load(foldername + 'clipcap_embeddings_curie.npy')\n",
    "blip_embeddings = np.load(foldername + 'blip_embeddings_curie.npy')\n",
    "microsoft_api_embeddings = np.load(foldername + 'microsoft_api_embeddings_curie.npy')\n",
    "\n",
    "ofa_sampled_idx = random.sample(range(0, 1000), 400)\n",
    "git_sampled_idx = random.sample(range(0, 1000), 400)\n",
    "clipcap_sampled_idx = random.sample(range(0, 1000), 400)\n",
    "blip_sampled_idx = random.sample(range(0, 1000), 400)\n",
    "microsoft_api_sampled_idx = random.sample(range(0, 1000), 400)\n",
    "\n",
    "embed = []\n",
    "labels = []\n",
    "modelname = []\n",
    "\n",
    "for embedding in human_embeddings:\n",
    "    embed.append(embedding)\n",
    "    labels.append(0)\n",
    "    modelname.append('human')\n",
    "    \n",
    "for idx in ofa_sampled_idx:\n",
    "    embed.append(ofa_embeddings[idx])\n",
    "    labels.append(1)\n",
    "    modelname.append('ofa')\n",
    "    \n",
    "for idx in git_sampled_idx:\n",
    "    embed.append(git_embeddings[idx])\n",
    "    labels.append(1)\n",
    "    modelname.append('git')\n",
    "    \n",
    "for idx in clipcap_sampled_idx:\n",
    "    embed.append(clipcap_embeddings[idx])\n",
    "    labels.append(1)\n",
    "    modelname.append('clipcap')\n",
    "    \n",
    "for idx in blip_sampled_idx:\n",
    "    embed.append(blip_embeddings[idx])\n",
    "    labels.append(1)\n",
    "    modelname.append('blip')\n",
    "    \n",
    "for idx in microsoft_api_sampled_idx:\n",
    "    embed.append(microsoft_api_embeddings[idx])\n",
    "    labels.append(1)\n",
    "    modelname.append('microsoft_api')\n",
    "    \n",
    "embed = np.vstack(embed)\n",
    "print(embed.shape)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c700aef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 4096)\n",
      "4000\n",
      "4000\n",
      "<class 'list'>\n",
      "4096\n",
      "['ofa', 'microsoft_api', 'blip', 'clipcap', 'git', 'human']\n",
      "leaving: ofa\n",
      "testing set.....\n",
      "training set.....\n",
      "Average Accuracy: 0.6471428571428571\n",
      "Standard Deviation of Accuracy: 0.012771312148490031\n",
      "reversing the training and testing set\n",
      "Average Accuracy: 0.39692307692307693\n",
      "Standard Deviation of Accuracy: 0.009595174025940054\n",
      "leaving: microsoft_api\n",
      "testing set.....\n",
      "training set.....\n",
      "Average Accuracy: 0.6278571428571429\n",
      "Standard Deviation of Accuracy: 0.012918772360417672\n",
      "reversing the training and testing set\n",
      "Average Accuracy: 0.4169230769230769\n",
      "Standard Deviation of Accuracy: 0.009669504498721563\n",
      "leaving: blip\n",
      "testing set.....\n",
      "training set.....\n"
     ]
    }
   ],
   "source": [
    "print(embed.shape)\n",
    "print(len(labels))\n",
    "print(len(modelname))\n",
    "print(type(modelname))\n",
    "\n",
    "featuredim = embed.shape[1]\n",
    "print(featuredim)\n",
    "\n",
    "unique_elements = list(set(modelname))\n",
    "print(unique_elements)\n",
    "\n",
    "def find_indices(lst, element):\n",
    "    indices = [index for index, value in enumerate(lst) if value == element]\n",
    "    return indices\n",
    "\n",
    "\n",
    "#########################################################################################################\n",
    "############################### LEAVE one model out; train on the rest and test on the one\n",
    "Dict_model_ind={}\n",
    "ResultMat = []\n",
    "\n",
    "for model in unique_elements:\n",
    "    \n",
    "    indicesA = [i for i, elem in enumerate(modelname) if (elem != model) and (elem != 'human')]\n",
    "    indicesB = [i for i, elem in enumerate(modelname) if (elem == 'human')]\n",
    "    # Determine the number of elements to choose (half of the list)\n",
    "    num_elements_to_choose = len(indicesB) // 2\n",
    "    # Randomly shuffle the list\n",
    "    random.shuffle(indicesB)\n",
    "\n",
    "    # Select the first half of the shuffled list\n",
    "    selected_elements_train_human = indicesB[:num_elements_to_choose]\n",
    "    selected_elements_test_human = indicesB[num_elements_to_choose:]\n",
    "    \n",
    "    indicesT = find_indices(modelname, model) \n",
    "    Dict_model_ind[model] = indicesT + selected_elements_test_human        #test set\n",
    "    Dict_model_ind[model + '_opp'] = indicesA + selected_elements_train_human #train set\n",
    "    #print(len(indices))\n",
    "    #print(indices)\n",
    "\n",
    "#print(Dict_model_ind)\n",
    "\n",
    "\n",
    "for targetmodel in unique_elements:\n",
    "    \n",
    "    \n",
    "    if targetmodel == 'human':\n",
    "        continue\n",
    "    else:\n",
    "        \n",
    "        result = {}\n",
    "        ################# LEAVE one more out; train on the rest; and test on the remaining one model\n",
    "        print('leaving: ' + targetmodel)  \n",
    "        result['test'] = [targetmodel, 'human']\n",
    "        print('testing set.....')\n",
    "        ind_test = Dict_model_ind[targetmodel]\n",
    "        #print(ind_test)\n",
    "        X_test = embed[ind_test, :]\n",
    "        #print(type(X_test))\n",
    "        y_test = labels[ind_test]\n",
    "        #print(modelname[ind_test])\n",
    "\n",
    "        print('training set.....')\n",
    "        #print(rest)\n",
    "        ind_train = Dict_model_ind[targetmodel + '_opp']                \n",
    "        X_train = embed[ind_train,:]\n",
    "        #print(X_train.shape)\n",
    "        y_train = labels[ind_train]\n",
    "        #print(y_train)\n",
    "        selectedMname = [modelname[i] for i in ind_train]\n",
    "        allTrainModels = list(set(selectedMname))\n",
    "        result['train'] = allTrainModels\n",
    "         \n",
    "        # Create an SVM classifier\n",
    "        clf = SVC(kernel='rbf')\n",
    "        \n",
    "#         print(X_train.shape)\n",
    "#         print(y_train.shape)\n",
    "        #print(y_train)\n",
    "#         nan_count = np.sum(np.isnan(y_train))\n",
    "\n",
    "#         print(\"Number of NaN values in y_train:\", nan_count)\n",
    "\n",
    "        # Train the classifier on the training data\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        y_pred = clf.predict(X_test)\n",
    "        #print(y_pred)\n",
    "        #print(y_test)\n",
    "\n",
    "        # Calculate the accuracy of the classifier\n",
    "        accuracies = (y_test == y_pred).astype(float)\n",
    "\n",
    "        # Calculate average accuracy\n",
    "        accuracy = np.mean(accuracies)\n",
    "\n",
    "        # Calculate standard deviation of accuracy\n",
    "        std_deviation = np.std(accuracies)/math.sqrt(len(accuracies))\n",
    "\n",
    "        print(\"Average Accuracy:\", accuracy)\n",
    "        print(\"Standard Deviation of Accuracy:\", std_deviation)\n",
    "\n",
    "        result['accu'] = accuracy\n",
    "        result['std'] = std_deviation\n",
    "        result['flag'] = 'test'\n",
    "\n",
    "        ResultMat.append(result)\n",
    "        \n",
    "        ############################### do the reverse; train on single; test on multiple   \n",
    "        print('reversing the training and testing set')       \n",
    "        result = {} \n",
    "        # Create an SVM classifier\n",
    "        clf = SVC(kernel='rbf')\n",
    "        \n",
    "        # Train the classifier on the training data\n",
    "        clf.fit(X_test, y_test)\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        y_pred = clf.predict(X_train)\n",
    "        \n",
    "        # Calculate the accuracy of the classifier\n",
    "        # Calculate the accuracy of the classifier\n",
    "        accuracies = (y_train == y_pred).astype(float)\n",
    "        #print(accuracies)\n",
    "        # Calculate average accuracy\n",
    "        accuracy = np.mean(accuracies)\n",
    "\n",
    "        # Calculate standard deviation of accuracy\n",
    "        std_deviation = np.std(accuracies)/math.sqrt(len(accuracies))\n",
    "\n",
    "        print(\"Average Accuracy:\", accuracy)\n",
    "        print(\"Standard Deviation of Accuracy:\", std_deviation)\n",
    "                \n",
    "        result['train'] = [targetmodel, 'human']\n",
    "        result['test'] = allTrainModels\n",
    "        result['accu'] = accuracy\n",
    "        result['std'] = std_deviation\n",
    "        result['flag'] = 'train'\n",
    "\n",
    "        ResultMat.append(result)\n",
    "        \n",
    "print(ResultMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f4bf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "### plots for grouping demographic information\n",
    "def plot_res_demographics(plotname, ResultMat):\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from matplotlib.patches import Rectangle\n",
    "    \n",
    "    modelist = ['microsoft_api', 'blip', 'git', 'ofa', 'clipcap']\n",
    "        \n",
    "    for condition in ['train','test']:\n",
    "        top1 = []\n",
    "        top1_std = []\n",
    "        for selectedM in modelist:\n",
    "            for result in ResultMat:\n",
    "                if result['flag'] == condition:\n",
    "                    if selectedM in result[condition]:\n",
    "#                         print(result['flag'])\n",
    "#                         print(condition)\n",
    "#                         print(result[condition])\n",
    "                        #chancenum = 1/(len(result['test']))\n",
    "                        top1.append(result['accu'])\n",
    "                        top1_std.append(result['std'])\n",
    "                \n",
    "        print(top1)        \n",
    "        ######### everything is ready for plotting                \n",
    "        years = list(range(1, len(modelist)))\n",
    "        strtask = modelist\n",
    "        # Figure Size\n",
    "        fig, ax = plt.subplots(layout='constrained')\n",
    "        #x = np.arange(len(strtask))  # the label locations\n",
    "\n",
    "        width = 0.2  # the width of the bars\n",
    "        print(len(strtask))\n",
    "        ax.bar(strtask, top1, yerr=top1_std, color ='black', width = 0.3,align='center',\n",
    "       alpha=0.5,\n",
    "       ecolor='black',\n",
    "       capsize=8)   \n",
    "\n",
    "        #ax.set_xticks(x, strtask)\n",
    "        #ax.legend(loc='upper left', ncols=len(condition_chosen_list))\n",
    "\n",
    "        plt.ylabel('Top-1 Accuracy')\n",
    "        plt.xticks(rotation = 90) # Rotates X-Axis Ticks by 45-degrees\n",
    "\n",
    "        plt.ylim(0.25, 1)\n",
    "        y_ticks = [0.3,0.5,0.7,0.9]\n",
    "        ax.set_yticks(y_ticks)\n",
    "        #plt.xlim(0.5, len(years)+0.5)\n",
    "\n",
    "        #draw chance 0.5 \n",
    "        chancex =np.arange(len(years)+2)-0.5\n",
    "        plt.plot(chancex, np.arange(len(chancex))*0+0.5, 'k--')#, label='chance (50%)')\n",
    "        #plt.legend()\n",
    "\n",
    "        fig.tight_layout()\n",
    "\n",
    "        fig.set_figwidth(7)\n",
    "        fig.set_figheight(5)\n",
    "\n",
    "        #fig.legend(loc='upper center', bbox_to_anchor=(0.55, 1.0), ncol=3, fancybox=True, shadow=True,frameon=False)\n",
    "\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "\n",
    "        plt.savefig(plotname + '_' + condition + '.eps', format='eps', bbox_inches='tight')\n",
    "        plt.savefig(plotname + '_' + condition + '.png',  bbox_inches='tight')\n",
    "        plt.show()\n",
    "#     fig.savefig('../' + plotname + '.png', bbox_inches='tight')\n",
    "#     fig.savefig('Human_judge_bars_Giorgia'+condition_chosen+'.pdf', bbox_inches='tight')\n",
    "    \n",
    "#     fig.savefig('Human_judge_bars_Giorgia'+condition_chosen+'.png', bbox_inches='tight')\n",
    "\n",
    "#======================AGE=======\n",
    "#condition_list = ['ageL35','ageG35L45','ageG45','F','M','school','bachelor','postgrad','US','nonUS','wGenderQ','woGenderQ']\n",
    "key = 'AIjudge'\n",
    "plotpathname = './plots/Task1_' + key + '_TrainTestSplits_BarPlotOverall' #for saving the plots\n",
    "facebarcolor = ['dimgray','darkgrey','lightgrey']\n",
    "\n",
    "plot_res_demographics(plotpathname, ResultMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5fa079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
