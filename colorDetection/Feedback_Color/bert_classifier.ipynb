{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import models\n",
    "from torch import nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_to_code = {}\n",
    "agent_to_code['humans'] = 'a'\n",
    "agent_to_code['azure'] = 'b'\n",
    "agent_to_code['histogram'] = 'c'\n",
    "agent_to_code['google'] = 'd'\n",
    "\n",
    "code_to_agent = {}\n",
    "code_to_agent['a'] = 'humans'\n",
    "code_to_agent['b'] = 'azure'\n",
    "code_to_agent['c'] = 'histogram'\n",
    "code_to_agent['d'] = 'google'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impath = \"static/dataset/coco_val_set/%s.jpg\"%fp.split('/')[-1].split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('color_to_bert.p','rb') as F:\n",
    "    color_to_embedding = pickle.load(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_to_embedding['none'] = color_to_embedding['white']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_18 = models.resnet18(pretrained=True)\n",
    "feature_model = nn.Sequential(*list(resnet_18.children())[:-1])\n",
    "feature_model.eval();\n",
    "scaler = transforms.Resize((224, 224))\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "to_tensor = transforms.ToTensor()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_embedding(impath):\n",
    "    img = Image.open(impath).convert('RGB')\n",
    "    t_img = Variable(normalize(to_tensor(scaler(img))).unsqueeze(0))\n",
    "    img_embedding = feature_model(t_img)\n",
    "    final_embedding = img_embedding[0,:,0,0]\n",
    "    return final_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impath_to_embeddings = {}\n",
    "# for htmlname in tqdm(os.listdir('static/responses_color/')):\n",
    "#     imname = htmlname.split('_')[0]\n",
    "#     impath = \"static/dataset/coco_val_set/%s.jpg\"%imname\n",
    "#     if not impath in impath_to_embeddings.keys():\n",
    "#         im_embedding = get_image_embedding(impath)\n",
    "#         impath_to_embeddings[impath] = 'done'\n",
    "#         with open('image_embeddings/%s.p'%imname,'wb') as F:\n",
    "#             pickle.dump(im_embedding,F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "# model = AutoModel.from_pretrained(\"distilbert-base-uncased\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.mkdir('image_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('impath_to_embeddings.p','rb') as F:\n",
    "#     impath_to_embeddings = pickle.load(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(allowed_algorithms = ['azure','histogram','google']):\n",
    "    human_data = []\n",
    "    ai_data = []\n",
    "\n",
    "    for file in os.listdir('static/responses_color/'):\n",
    "        fp = \"static/responses_color/%s\"%file\n",
    "        if fp.endswith('html'):\n",
    "            with open(fp,'r') as F:\n",
    "                contents = F.readlines()\n",
    "                color = contents[0].split(': ')[2].split('<')[0]\n",
    "                speaker_type = code_to_agent[fp.split('_')[2]]\n",
    "                impath = \"static/dataset/coco_val_set/%s.jpg\"%fp.split('/')[-1].split('_')[0]\n",
    "            if speaker_type == 'humans':\n",
    "                human_data.append([impath,color])\n",
    "            else:\n",
    "                if speaker_type in allowed_algorithms:\n",
    "                    ai_data.append([impath,color])\n",
    "    return human_data, ai_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitted_embeddings(speaker_data,label_val = 0):\n",
    "    train_data = speaker_data[:int(0.9*len(speaker_data))]\n",
    "    val_data = speaker_data[int(0.9*len(speaker_data)):]\n",
    "    \n",
    "    X_train = np.zeros((len(train_data),1280))\n",
    "    X_val = np.zeros((len(val_data),1280))\n",
    "    \n",
    "    Y_train = np.ones(len(train_data))*label_val\n",
    "    Y_val = np.ones(len(val_data))*label_val\n",
    "    \n",
    "    train_im_paths = []\n",
    "    test_im_paths = []\n",
    "    \n",
    "    for split in ['train','val']:\n",
    "        if split == 'train':\n",
    "            split_data = train_data\n",
    "        elif split =='val':\n",
    "            split_data = val_data\n",
    "\n",
    "        for i in tqdm(range(len(split_data))):\n",
    "            data = split_data[i]\n",
    "            impath = data[0]\n",
    "            color = data[1]\n",
    "            embedding_path = impath.replace('static/dataset/coco','image_embeddings').replace('.jpg','.p')\n",
    "            image_features = get_image_embedding(impath)\n",
    "            cls_train = color_to_embedding[color]\n",
    "            concatenated_features = torch.hstack((image_features, cls_train[0]))\n",
    "            \n",
    "            if split == 'train':\n",
    "                X_train[i] = concatenated_features.detach()\n",
    "                train_im_paths.append(impath)\n",
    "            elif split == 'val':\n",
    "                X_val[i] = concatenated_features.detach()\n",
    "                test_im_paths.append(impath)\n",
    "    \n",
    "    return X_train, Y_train, X_val, Y_val, train_im_paths, test_im_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_colors = []\n",
    "# for i in tqdm(range(len(human_data))):\n",
    "#     data = human_data[i]\n",
    "#     impath = data[0]\n",
    "#     color = data[1]\n",
    "#     all_colors.append(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color_to_embedding = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for possible_color in list(set(all_colors)):\n",
    "#     tokenized_color = tokenizer([possible_color], padding = True, truncation = True, return_tensors=\"pt\")\n",
    "#     tokenized_train = {k:torch.tensor(v).to(device) for k,v in tokenized_color.items()}\n",
    "#     with torch.no_grad():\n",
    "#         hidden_train = model(**tokenized_train) \n",
    "#     cls_train = hidden_train.last_hidden_state[:,0,:]\n",
    "#     color_to_embedding[possible_color] = cls_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('color_to_bert.p','wb') as F:\n",
    "#     pickle.dump(color_to_embedding,F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_data(human_data, ai_data):\n",
    "    random.shuffle(human_data)\n",
    "    random.shuffle(ai_data)\n",
    "    x_trainh,y_trainh,x_valh,y_valh,train_im_paths, test_im_paths = splitted_embeddings(human_data)\n",
    "    x_traina,y_traina,x_vala,y_vala, train_im_paths, test_im_paths = splitted_embeddings(ai_data,1)\n",
    "    x_train = np.vstack((x_trainh,x_traina))\n",
    "    x_val = np.vstack((x_valh,x_vala))\n",
    "    y_train = np.hstack((y_trainh,y_traina))\n",
    "    y_val = np.hstack((y_valh,y_vala))\n",
    "    \n",
    "    return x_train,y_train,x_val,y_val,train_im_paths,test_im_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_and_score(x_train,y_train,x_val,y_val, algo = 'SVM'):    \n",
    "    if algo == 'RF':\n",
    "        rf = RandomForestClassifier()\n",
    "        rf.fit(x_train,y_train)\n",
    "        predictions = rf.predict(x_val)\n",
    "        score = rf.score(x_val,y_val) \n",
    "    elif algo == 'SVM':\n",
    "        svm = SVC()\n",
    "        svm.fit(x_train,y_train)\n",
    "        predictions = svm.predict(x_val)\n",
    "        score = svm.score(x_val,y_val) \n",
    "        \n",
    "    conf_mat = confusion_matrix(y_val, predictions, normalize='true')\n",
    "    return conf_mat, score, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_conf_mat = np.zeros((5,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_data, ai_data = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "873"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(human_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [01:02<00:00, 12.65it/s]\n",
      "100%|██████████| 88/88 [00:06<00:00, 12.58it/s]\n",
      "100%|██████████| 785/785 [01:01<00:00, 12.69it/s]\n",
      "100%|██████████| 88/88 [00:07<00:00, 12.48it/s]\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(ai_data)\n",
    "ai_data = ai_data[:len(human_data)]\n",
    "x_train,y_train,x_val,y_val,train_im_paths,test_im_paths = embed_data(human_data, ai_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_conf, svm_score,predictions = classify_and_score(x_train,y_train,x_val,y_val,'RF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_conf, svm_score,predictions = classify_and_score(x_train,y_train,x_val,y_val,'SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38636364, 0.61363636],\n",
       "       [0.63636364, 0.36363636]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_confs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_confs['all'] = svm_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38636364, 0.61363636],\n",
       "       [0.63636364, 0.36363636]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_conf_mat[0] = svm_conf[0]\n",
    "result_conf_mat[1] = svm_conf[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = y_val.astype('int')\n",
    "predictions = predictions.astype('int')\n",
    "all_stds['all'] = np.std(y_val == predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Humans vs Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [01:01<00:00, 12.67it/s]\n",
      "100%|██████████| 88/88 [00:06<00:00, 12.74it/s]\n",
      "100%|██████████| 785/785 [01:02<00:00, 12.61it/s]\n",
      "100%|██████████| 88/88 [00:07<00:00, 12.53it/s]\n"
     ]
    }
   ],
   "source": [
    "human_data, ai_data = read_data(['azure'])\n",
    "x_train,y_train,x_val,y_val,train_im_paths,test_im_paths = embed_data(human_data, ai_data)\n",
    "svm_conf, svm_score,predictions = classify_and_score(x_train,y_train,x_val,y_val,'SVM')\n",
    "result_conf_mat[2] = svm_conf[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_confs['azure'] = svm_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = y_val.astype('int')\n",
    "predictions = predictions.astype('int')\n",
    "all_stds['azure'] = np.std(y_val == predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Humans vs Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [01:02<00:00, 12.59it/s]\n",
      "100%|██████████| 88/88 [00:07<00:00, 12.21it/s]\n",
      "100%|██████████| 785/785 [01:02<00:00, 12.66it/s]\n",
      "100%|██████████| 88/88 [00:06<00:00, 12.77it/s]\n"
     ]
    }
   ],
   "source": [
    "human_data, ai_data= read_data(['histogram'])\n",
    "x_train,y_train,x_val,y_val,train_im_paths,test_im_paths = embed_data(human_data, ai_data)\n",
    "svm_conf, svm_score,predictions = classify_and_score(x_train,y_train,x_val,y_val,'RF')\n",
    "result_conf_mat[3] = svm_conf[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = y_val.astype('int')\n",
    "predictions = predictions.astype('int')\n",
    "all_stds['histogram'] = np.std(y_val == predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_confs['histogram'] = svm_conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Humans vs Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [01:01<00:00, 12.68it/s]\n",
      "100%|██████████| 88/88 [00:06<00:00, 12.67it/s]\n",
      "100%|██████████| 785/785 [01:01<00:00, 12.76it/s]\n",
      "100%|██████████| 88/88 [00:06<00:00, 12.69it/s]\n"
     ]
    }
   ],
   "source": [
    "human_data, ai_data = read_data(['google'])\n",
    "x_train,y_train,x_val,y_val,train_im_paths,test_im_paths = embed_data(human_data, ai_data)\n",
    "svm_conf, svm_score,predictions = classify_and_score(x_train,y_train,x_val,y_val,'RF')\n",
    "result_conf_mat[4] = svm_conf[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = y_val.astype('int')\n",
    "predictions = predictions.astype('int')\n",
    "all_stds['google'] = np.std(y_val == predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_confs['google'] = svm_conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelist = ['Azure','Histogram','Google']\n",
    "\n",
    "# plotname = 'dominant_color_recognition'\n",
    "\n",
    "# import os\n",
    "# os.makedirs('figures',exist_ok=True)\n",
    "\n",
    "# #plot confusion matrix\n",
    "# import seaborn as sn\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# df_cm = pd.DataFrame(result_conf_mat, index = [i for i in ['Human','AI']+modelist],\n",
    "#                   columns = [i for i in ['Human','AI']])\n",
    "# plt.figure(figsize =  (1.2,3.5))\n",
    "# sn.heatmap(df_cm, annot=True,robust=True, cmap='RdBu_r', vmin=0, vmax=1)\n",
    "# plt.xlabel(\"Predicted\")\n",
    "# plt.ylabel(\"Ground Truth\")\n",
    "\n",
    "# plt.savefig('figures/' + plotname + '_bert_confmat.pdf', bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': 0.4841229182759271,\n",
       " 'azure': 0.4758840728858723,\n",
       " 'histogram': 0.4926827701305081,\n",
       " 'google': 0.4953294254023492}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.38636364 0.61363636]\n",
      " [0.63636364 0.36363636]\n",
      " [0.72727273 0.27272727]\n",
      " [0.44318182 0.55681818]\n",
      " [0.57954545 0.42045455]]\n",
      "[0.375, 0.32954545454545453, 0.47159090909090906, 0.40340909090909094]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 180x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compute top 1 accuracy for each AI model and also overall AI\n",
    "top1 = []\n",
    "print(result_conf_mat)\n",
    "for i in range(1+len(modelist)):\n",
    "    #print(i)\n",
    "    top1.append((result_conf_mat[0][0]+result_conf_mat[i+1][1])/2)\n",
    "print(top1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    " \n",
    "#data\n",
    "#x-axis\n",
    "years = list(range(1, 2+len(modelist)))\n",
    "strtask = ['AI'] + modelist\n",
    "#print(years)\n",
    "#print(strtask)\n",
    "\n",
    "# Figure Size\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "ax.add_patch(Rectangle((-0.5, 0.45), len(top1), 0.1,facecolor='yellow'))\n",
    "\n",
    "#bar chart properties\n",
    "# ax.bar(strtask, top1, color ='black', width = 0.3)\n",
    "ax.bar(strtask, top1, yerr=all_stds.values(),\n",
    "       align='center', alpha=0.5, ecolor='black', capsize=10,\n",
    "       color ='black', width = 0.3)\n",
    "  \n",
    "plt.ylabel('Top-1 Accuracy')\n",
    "plt.xticks(rotation = 90) # Rotates X-Axis Ticks by 45-degrees\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "#plt.xlim(0.5, len(years)+0.5)\n",
    "\n",
    "#draw chance 0.5 \n",
    "# chancex =np.arange(len(years))\n",
    "# plt.plot(chancex, np.arange(len(chancex))*0+0.5, 'k--', label='chance (50%)')\n",
    "#plt.legend()\n",
    " \n",
    "fig.tight_layout()\n",
    "\n",
    "fig.set_figwidth(2.5)\n",
    "fig.set_figheight(5)\n",
    "\n",
    "fig.legend(loc='upper center', bbox_to_anchor=(0.55, 1.0), ncol=3, fancybox=True, shadow=True,frameon=False)\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig('figures/' + plotname + '_bert.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
