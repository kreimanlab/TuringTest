{"cells":[{"cell_type":"code","execution_count":null,"id":"adaa4b17","metadata":{"id":"adaa4b17"},"outputs":[],"source":["import csv\n","import json\n","import sqlite3\n","\n","\n","calculation_type = 'drop_training' # exclude training samples when gather human results\n","keep_catch_trials = False\n","\n","results = {'inlab':[], 'inlab_gender':[], 'inlab_nogender':[], 'mturk':[], 'machine':[], 'combined':[], 'mturk-feedback':[]}\n","\n","############# for jason file processing\n","jsonpath = './Data_all/'\n","\n","\n","# if calculation_type == 'drop_training':\n","#     with open(jsonpath+\"feedback_train_samples.json\", \"r\") as fp:\n","#         feedback_train_samples = json.load(fp)[\"feedback_train_samples\"]\n","#     with open(jsonpath+\"feedback_test_samples.json\", \"r\") as fp:\n","#         feedback_test_samples = json.load(fp)[\"feedback_test_samples\"]\n","# filenames = {#'inlab': ['turing_test_img_caption_inlab_gender_15','turing_test_img_caption_inlab_no_gender_15'],\n","#                  #'inlab_gender': ['turing_test_img_caption_inlab_gender_15'],\n","#                  #'inlab_nogender': ['turing_test_img_caption_inlab_no_gender_15'],\n","#                  #'mturk':['turing_live_mturk'],\n","#                  'mturk-feedback':['turing_live_feedback']}\n","\n","filenames = {}\n","\n","\n","#Images 1-250 are from COCO test set,\n","# images 251-500 are nocaps val in-domain,\n","# images 501-750 are nocaps val near-domain,\n","# images 751-1000 are nocaps val out-domain\n","\n"]},{"cell_type":"code","execution_count":null,"id":"b15a7709","metadata":{"id":"b15a7709","outputId":"ca2e2001-a6d9-40bd-d465-c51f1dcefbbd"},"outputs":[{"name":"stdout","output_type":"stream","text":["All data is extracted.\n","inlab\n","There are [0]\n","inlab_gender\n","There are [0]\n","inlab_nogender\n","There are [0]\n","mturk\n","There are [1930]\n","machine\n","There are [0]\n","combined\n","There are [0]\n","mturk-feedback\n","There are [2000]\n","machine-feedback\n","There are [4000]\n","machine-zeroshot\n","There are [1500]\n","mturk-chatgpt\n","There are [3000]\n","Compilation completed! Results are saved to folder!\n"]}],"source":["\n","for key in filenames:\n","    print(\"=======================\")\n","    print(key)\n","\n","    count = 0\n","    trials_dict = {}\n","    workercount = 0\n","\n","\n","    for dbfilename in filenames[key]:\n","        #print(\"=======================\")\n","        #print(jasonfilename)\n","        conn = sqlite3.connect(jsonpath + dbfilename + \".db\")\n","        cursor = conn.cursor()\n","        cursor.execute(\"select * from imgcaption;\")\n","        all_data = cursor.fetchall()\n","\n","        for i in range(0, len(all_data)):\n","            nTrial = 0\n","            if (all_data[i][15] == 7) or (all_data[i][15] == 5): #check status\n","                data_dict = json.loads(all_data[i][17])\n","                workercount += 1\n","                for dat in data_dict['data']:\n","                    if dat['trialdata']['phase'] == 'TEST':\n","                        nTrial += 1\n","#                         print(dat)\n","                        if calculation_type == \"drop_training\" and key == \"mturk-feedback\" and\\\n","                            nTrial<=40:\n","#                             feedback_train_samples.append()\n","                            continue\n","#                         elif calculation_type == \"drop_training\" and key != \"mturk-feedback\" and\\\n","#                             [dat['trialdata']['imageID'].split('/')[-1],\\\n","#                              dat['trialdata']['human_grountruth'],\\\n","#                              dat['trialdata']['ai_grountruth']] not in feedback_test_samples:\n","#                             train_samples.append([dat['trialdata']['imageID'].split('/')[-1],\\\n","#                              dat['trialdata']['human_grountruth'],\\\n","#                              dat['trialdata']['ai_grountruth']])\n","#                             continue\n","                        elif key == \"mturk-feedback\" and not keep_catch_trials and dat['trialdata']['machine_groundtruth'] == \"catch\":\n","                            continue\n","\n","                        count += 1\n","                        trial_data = {}\n","                        trial_data['workerID'] = data_dict['workerId']\n","                        trial_data['workerData'] = data_dict['questiondata']\n","                        trial_data['trialData'] = dat['trialdata']\n","\n","                        imagepathname_id = int(trial_data['trialData']['imageID'][-8:-4])\n","\n","                        if imagepathname_id<= 250:\n","                            trial_data['workerData']['imagetype'] = 'COCO'\n","                        elif imagepathname_id<= 500:\n","                            trial_data['workerData']['imagetype'] = 'in-domain'\n","                        elif imagepathname_id<= 750:\n","                            trial_data['workerData']['imagetype'] = 'near-domain'\n","                        else:\n","                            trial_data['workerData']['imagetype'] = 'out-domain'\n","\n","\n","                        # Get rid of typo in the key in db file\n","                        if 'ai_grountruth' in list(trial_data['trialData'].keys()):\n","                            trial_data['trialData']['machine_groundtruth'] = trial_data['trialData']['ai_grountruth']\n","                            del trial_data['trialData']['ai_grountruth']\n","\n","                        # Get rid of typo in the key in db file\n","                        if trial_data['trialData']['response_speaker'] == 'ai':\n","                            trial_data['trialData']['response_speaker'] = 'machine'\n","\n","                        trials_dict['Trial_'+str(count)] = trial_data\n","\n","\n","        conn.close()\n","        results[key] = trials_dict\n","        #json.dump(trials_dict, open(\"./turing_inlab_no_gender_img_caption_half.json\",\"w\"))\n","    print(workercount, ' workers')\n","\n","########### AI jason files\n","json_file_path = './Data_all/AIjudge_compiled_Word_Feedback_testphase.json'\n","\n","with open(json_file_path, 'r') as j:\n","     contents = json.loads(j.read())\n","results['machine-feedback'] = contents\n","#print(contents)\n","json_file_path = './Data_all/ai_judge_zeroshot_wordassoc.json'\n","\n","with open(json_file_path, 'r') as j:\n","     contents = json.loads(j.read())\n","results['machine-zeroshot'] = contents\n","# #save combined results\n","# count = 0\n","# trials_dict = {}\n","# for ke in ['mturk','mturk-feedback']:\n","#     for it in results[ke]:\n","#         count = count + 1\n","#         trialin = results[ke][it]\n","#         trials_dict['Trial_'+str(count)] = trialin\n","\n","# results['combined'] = trials_dict\n","with open(\"./savedResults/compiled.json\",'r') as f:\n","    contents = json.loads(f.read())\n","\n","results[\"mturk\"] = contents[\"mturk\"]\n","\n","with open(\"./Data_all/humanjudge_Word_Feedback_testphase.json\",'r') as f:\n","    contents = json.loads(f.read())\n","\n","results[\"mturk-feedback\"] = contents\n","\n","with open(\"./Data_all/humanjudge_Word_ChatGPT_testphase.json\",'r') as f:\n","    contents = json.loads(f.read())\n","\n","results[\"mturk-chatgpt\"] = contents\n","\n","\n","\n","print('All data is extracted.')\n","for key in results:\n","    print(key)\n","    print('There are [' + str(len(results[key])) + ']')\n","\n","#save the compiled results as jason\n","# with open(\"./savedResults/compiled_feedback_{}.json\".format('rebuttal_allresults'), \"w\") as fp:\n","#     json.dump(results,fp)\n","\n","print('Compilation completed! Results are saved to folder!')"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}