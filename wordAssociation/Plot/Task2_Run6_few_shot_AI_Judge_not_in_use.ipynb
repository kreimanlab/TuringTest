{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d147545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import openai\n",
    "import seaborn as sn\n",
    "\n",
    "load_dotenv()\n",
    "load_dotenv(\"variables.env\")\n",
    "openai.api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(model=model, messages=messages,temperature=0)\n",
    "\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "\n",
    "prompt1 = 'You are presented with a pair of words consisting of cueword and guessword.'+\\\n",
    "' Given the pair of words, please predict binary label whether the guessword is come up with a human or an AI.'+\\\n",
    "' The pair of words is represented as <cueword, guessword>. For example, <apple, phone> '+\\\n",
    "'where apple is cueword and phone is guessword.'+\\\n",
    "' Please output whether the agent coming up with the guessword is a human or AI in the following example: '\n",
    "\n",
    "\n",
    "cue_words_list = np.load('Data_all/all_cue_words_october_1.npy')\n",
    "CueGuessWords = {}\n",
    "\n",
    "for w in cue_words_list:\n",
    "    #print(w)\n",
    "    CueGuessWords[w] = {'human':[],'AI':[]}\n",
    "\n",
    "    \n",
    "numfiles = 150\n",
    "numfolders = 5\n",
    "\n",
    "for identity in ['human','AI']:\n",
    "    for fo in range(numfolders):\n",
    "        for fi in range(numfiles):\n",
    "            filename = identity + '/' + str(fo) + '/' + str(fi) + '.html'\n",
    "\n",
    "            with open('./dataset/' + filename) as f:\n",
    "                lines = f.readlines()\n",
    "                #print(lines)\n",
    "                cueword = lines[0].split('<p>Cue: ')[1].split(';')[0]\n",
    "                #print(cueword)\n",
    "                guessword = lines[0].split('; Association: ')[1].split(' </p>')[0]\n",
    "                #print(guessword)\n",
    "                CueGuessWords[cueword][identity].append(guessword)\n",
    "\n",
    "#print(CueGuessWords)\n",
    "\n",
    "for w in cue_words_list:\n",
    "    #print(w)\n",
    "    strlistH = CueGuessWords[w]['human']\n",
    "    strlistM = CueGuessWords[w]['AI']\n",
    "    flag = bool(set(strlistH).intersection(strlistM))\n",
    "#     if not flag:\n",
    "#         print(w)\n",
    "#         print(strlistH)\n",
    "#         print(strlistM)\n",
    "    CueGuessWords[w]['flag'] = flag\n",
    "\n",
    "    \n",
    "H_responses_all = [] # all cases together\n",
    "AI_responses_all = []\n",
    "    \n",
    "for w in cue_words_list:\n",
    "    print('There are ' + str(len(cue_words_list)) + ' cue words.')\n",
    "    if not CueGuessWords[w]['flag']:\n",
    "        cueword = w\n",
    "        \n",
    "        for identity in ['human','AI']:\n",
    "            for guessword in CueGuessWords[cueword][identity]:\n",
    "                prompt2 = '<'+cueword+','+guessword+'>'\n",
    "                entireprompt = prompt1 + prompt2\n",
    "                print(entireprompt)\n",
    "                \n",
    "                response = get_completion(entirePrompt)\n",
    "                print(response)\n",
    "                \n",
    "                \n",
    "                #print(myList)\n",
    "                if 'AI' in response:\n",
    "                    conv1_Aclass = 'AI'\n",
    "                elif 'Human' in response or 'human' in response:\n",
    "                    conv1_Aclass = 'human'\n",
    "                else:\n",
    "                    print(\"Not found!\")\n",
    "                    continue\n",
    "                    \n",
    "                if identity == 'human':\n",
    "                    \n",
    "                    if conv1_Aclass == 'human':\n",
    "                        H_responses_all.append(1)\n",
    "                    else:\n",
    "                        H_responses_all.append(0)\n",
    "                        \n",
    "                else:\n",
    "                    if conv1_Aclass == 'human':\n",
    "                        AI_responses_all.append(0)\n",
    "                    else:\n",
    "                        AI_responses_all.append(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a20bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(H_responses_all) # all cases together\n",
    "print(AI_responses_all)\n",
    "\n",
    "modelist = ['Human (all)',           \n",
    "           'Machine (all)']\n",
    "\n",
    "###################3compute confusion matrix\n",
    "result_conf_mat = np.zeros((len(modelist),2),'float32')\n",
    "result_conf_mat[0][0] = H_responses_all\n",
    "result_conf_mat[0][1] = 1-H_responses_all\n",
    "result_conf_mat[1][0] = 1-AI_responses_all\n",
    "result_conf_mat[1][1] = AI_responses_all\n",
    "print(result_conf_mat)\n",
    "    \n",
    "df_cm = pd.DataFrame(result_conf_mat, index = [i for i in modelist],\n",
    "              columns = [i for i in ['Human','Machine']])\n",
    "plt.figure(figsize = (1.2,2.5))\n",
    "sn.heatmap(df_cm, annot=True,robust=True, cmap='RdBu_r', vmin=0, vmax=1)\n",
    "\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Ground Truth\")\n",
    "\n",
    "key = 'fewshotAIjudge'\n",
    "folderpath = './plots/Task2_' + key + '_' #for saving the plots\n",
    "plotname = 'fewshotAI_judge'\n",
    "plt.savefig(folderpath + plotname + '_overall_confmat.eps', format='eps', bbox_inches='tight')\n",
    "plt.savefig(folderpath + plotname + '_overall_confmat.png', bbox_inches='tight')\n",
    "#     plt.savefig('../' + plotname + '_confmat.png', bbox_inches='tight')\n",
    "#     plt.savefig('Human_judge_confmatGiorgia'+condition_chosen+'.pdf', bbox_inches='tight')\n",
    "#     plt.savefig('Human_judge_confmatGiorgia'+condition_chosen+'.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
